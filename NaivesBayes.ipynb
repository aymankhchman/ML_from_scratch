{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv',\n",
    "                  encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis = 1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['label','message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['encoded_label'] = [1 if label == 'spam' else 0 for label in data.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class formating_message:\n",
    "    \n",
    "    def __init__(self,bs = False):\n",
    "        self.bs = bs\n",
    "        \n",
    "    \n",
    "    def word_cleaner(self,message):\n",
    "        StopWords = stopwords.words('english')\n",
    "        if self.bs:\n",
    "            message = BeautifulSoup(message).get_text()\n",
    "        no_punc = re.sub('[^A-Za-z ]','',message)\n",
    "        no_punc = re.sub(' \\s+','',no_punc)\n",
    "        word_list = no_punc.split(' ')\n",
    "        word_lower = list(map(str.lower,word_list))\n",
    "        word_nost = [w for w in word_lower if (w not in StopWords and len(w) > 2)]\n",
    "        mess_back = ' '.join(word_nost)\n",
    "        \n",
    "        return mess_back\n",
    "    \n",
    "    def tokenizer(self,message):\n",
    "        word_token = []\n",
    "        message_cleaned = self.word_cleaner(message)\n",
    "        tokens = message_cleaned.split(' ')\n",
    "        if (len(tokens) > 0):\n",
    "            word_token.extend(tokens)\n",
    "        return set(word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = formating_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.message[0:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U dun say so early hor... U c already then say...'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.message[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wat', 'buffet', 'jurong', 'crazy', 'bugis', 'available', 'point', 'world', 'great', 'cine', 'amore', 'got'}\n",
      "{'joking', 'oni', 'wif', 'lar'}\n",
      "{'apply', 'tkts', 'toto', 'receive', 'ratetcs', 'comp', 'win', 'maytext', 'questionstd', 'overs', 'wkly', 'ina', 'free', 'txt', 'entry', 'final', 'cup'}\n",
      "{'dun', 'hor', 'say', 'already', 'early'}\n",
      "{'though', 'dont', 'think', 'nah', 'lives', 'around', 'goes', 'usf'}\n"
     ]
    }
   ],
   "source": [
    "for message in data.message[0:5]:\n",
    "    print(cleaner.tokenizer(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5572, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaivesBayesClassifier:\n",
    "    \n",
    "    def __init__(self,Tokenizer,salut):\n",
    "        self.Tokenizer = Tokenizer \n",
    "        self.salut = salut\n",
    "\n",
    "        \n",
    "    def fit(self,messages,labels):\n",
    "        self.classes = np.unique(labels)\n",
    "        self.n_classes = [] \n",
    "        \n",
    "        n = len(messages)\n",
    "        self.priors = []\n",
    "        \n",
    "        for label in self.classes:\n",
    "            self.n_classes.append(np.sum(labels == label))\n",
    "            \n",
    "        for lab in self.classes:\n",
    "            self.priors.append(self.n_classes[lab] / n)\n",
    "        \n",
    "        self.n = len(messages)\n",
    "        total_word = []\n",
    "        \n",
    "        self.counter_list = [None] * len(self.classes)\n",
    "        for lab in self.classes:\n",
    "            self.counter_list[lab] = Counter()\n",
    "            \n",
    "        for lab in self.classes:\n",
    "            for i in range(len(messages)):\n",
    "                if (labels[i] == lab):\n",
    "                    message_tokenized = self.Tokenizer.tokenizer(messages[i])\n",
    "                    for word in message_tokenized:\n",
    "                        if (word != ''):\n",
    "                            total_word.append(word)\n",
    "                            self.counter_list[lab][word] += 1\n",
    "        self.unique_word = set(total_word) \n",
    "        \n",
    "        for lab in self.classes:\n",
    "            for word in self.unique_word:\n",
    "                if word not in self.counter_list[lab].keys():\n",
    "                    self.counter_list[lab][word] = 0\n",
    "                \n",
    "                \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def _word_prob(self,message_test):\n",
    "        all_test_word = []\n",
    "        \n",
    "        for lab in self.classes:\n",
    "            self.n_classes.append(len(self.counter_list[lab]))\n",
    "            \n",
    "        for message in message_test:\n",
    "            mess_test_tok = self.Tokenizer.tokenizer(message)\n",
    "            for word in mess_test_tok:\n",
    "                all_test_word.append(word)\n",
    "                \n",
    "        unique_test_word = set(all_test_word)\n",
    "        n_train = len(self.unique_word)\n",
    "        word_not_in_train = [w for w in unique_test_word if w not in self.unique_word]\n",
    "        full_word = list(self.unique_word) + word_not_in_train\n",
    "        n_toadd = len(word_not_in_train)\n",
    "        \n",
    "        for lab in self.classes:\n",
    "            for word in full_word:\n",
    "                if word in word_not_in_train:\n",
    "                    self.counter_list[lab][word] = 100000 *(1 / (len(self.unique_word)+ n_toadd)) # avoid infinity for very small value\n",
    "                else:\n",
    "                    self.counter_list[lab][word]  = 100000 *((self.counter_list[lab][word] + 1) / (len(self.unique_word) + n_toadd))\n",
    "        \n",
    "        return self\n",
    "            \n",
    "            \n",
    "    def predict(self,message_test):\n",
    "        self._word_prob(message_test)\n",
    "        predict_classes = Counter()\n",
    "        predicted_class = []\n",
    "\n",
    "        for message in message_test:\n",
    "            mess_test = self.Tokenizer.tokenizer(message)\n",
    "            for lab in self.classes:\n",
    "                predict_sum = 0\n",
    "                for word in mess_test:\n",
    "                    predict_sum += np.log(self.counter_list[lab][word]) # avoid log(0) don't know where it's coming from\n",
    "                predict_classes[lab] = predict_sum + np.log(self.priors[lab])\n",
    "\n",
    "            predicted_class.append(predict_classes.most_common(1)[0][0])\n",
    "\n",
    "        return predicted_class                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = list(NB.unique_word) + ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test' in new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((data.encoded_label == 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaivesBayesClassifier(formating_message(),'Hey test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaivesBayesClassifier at 0x14944aa9f08>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.fit(data.message[0:3000],data.encoded_label[0:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8636666666666667, 0.13633333333333333]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted  = NB.predict(data.message[3000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572317262830482"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == data.encoded_label[3000:]) #Super cool !~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the algorithm on another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imdb = pd.read_csv('labeledTrainData.tsv',delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imdb = pd.read_csv('testData.tsv',delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = BeautifulSoup(train_imdb.review[0]).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_imdb = NaivesBayesClassifier(formating_message(bs = True),'Hey There :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaivesBayesClassifier at 0x14947d6db48>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_imdb.fit(train_imdb.review,train_imdb.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_imdb.priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_imdb = NB_imdb.predict(test_imdb.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 12222\n",
      "1 : 12778\n"
     ]
    }
   ],
   "source": [
    "count_classes(predicted_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(liste):\n",
    "    unique_class = np.unique(liste)\n",
    "    for cat in unique_class:\n",
    "        print(f'{cat} : {liste.count(cat)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame({\n",
    "    'id' : test_imdb.id,\n",
    "    'sentiment' : predicted_imdb\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.845 on kaggle :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
